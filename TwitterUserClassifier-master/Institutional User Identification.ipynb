{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Institutional User Identification with python and Scikit-Learn. \n",
    "This Notebook will perform the following tasks:\n",
    "- Clean Twitter description data.  This functionality (and how exactly we will clean/prepare our raw data can be seen in the `clean` method in the second block\n",
    "- Test the following models on our dataset:\n",
    " - Random Forest\n",
    " - Logistic Regression\n",
    " - Support Vector Machine (linear kernel)\n",
    " - Naive Bayes (Multinomial and Gaussian priors) \n",
    "- Save the results of each model to a well-formatted csv file\n",
    "- Evaluate the models automatically and save the results to a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The following two blocks of code can be skipped.  Block 1 imports all the necessary packages.  Block 2 contains the* `clean` * function, the *`read_data`* function, and the *`eval_model` *function*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, csv\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(string):\n",
    "    letters_only = re.sub(\"[^a-zA-Z#@]\", \" \", string)\n",
    "\n",
    "    words = letters_only.split()\n",
    "\n",
    "    for i in range(0, len(words)):\n",
    "        if \"#\" in words[i]:\n",
    "            s = words[i].split('#')\n",
    "            words[i] = '# '.join(s)\n",
    "        if \"@\" in words[i]:\n",
    "            s = words[i].split('@')\n",
    "            words[i] = '@ '.join(s)\n",
    "        if \"http\" in words[i]:\n",
    "            s = words[i].split('http')\n",
    "            words[i]= \"http\".join(s)\n",
    "            \n",
    "    total_stop_words = set(stopwords.words(\"english\"))\n",
    "    removed_stop_words = set(stopwords.words(\"english\")[0:20])\n",
    "    stop_words = total_stop_words - removed_stop_words\n",
    "    content_words = [w for w in words if not w in stop_words]\n",
    "\n",
    "    return \" \".join(content_words)\n",
    "\n",
    "def read_data(file):\n",
    "    data = pd.read_table(file)\n",
    "    data['Description'] = data.apply(lambda row: clean(row['Description']), axis = 1)\n",
    "    data['Personal'] = data.apply(lambda row:data['Personal'].astype(int))\n",
    "    return data\n",
    "\n",
    "def eval_model(name, classes, predictions):\n",
    "    TP, TN, FP, FN = 0, 0, 0, 0\n",
    "    classes = list(classes)\n",
    "    predictions = list(predictions)\n",
    "    \n",
    "    for i in range(0,len(classes)):\n",
    "        if (classes[i] == 1) & (predictions[i] == 1):\n",
    "            TP += 1\n",
    "        if (classes[i] == 0) & (predictions[i] == 0):\n",
    "            TN += 1\n",
    "        if (classes[i] == 1) & (predictions[i] == 0):\n",
    "            FN += 1\n",
    "        if (classes[i] == 0) & (predictions[i] == 1):\n",
    "            FP += 1\n",
    "   \n",
    "    accuracy= (TP + TN)/(TP + TN + FP + FN)\n",
    "    precision= (TP)/(TP+FP)\n",
    "    recall= TP / (TP+FN)\n",
    "    f_one= 2 * (precision*recall)/(precision + recall)\n",
    "    \n",
    "    scores = {\n",
    "        'Model Name': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f_one,\n",
    "        'Total TP type':TP,\n",
    "        'Total TN type':TN,\n",
    "        'Total FP type':FP,\n",
    "        'Total FN type':FN\n",
    "    }\n",
    "    \n",
    "    return scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block is divided into 3 parts:\n",
    "\n",
    "- Lines 1-5: load the data into pandas Dataframes (it does so by calling method above)\n",
    "- Lines 7-10: vectorize the user descriptions (find a numerical coding for each text-based description)\n",
    "- Line 12: Declare variable Y as the explanatory variable of the descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = str() \n",
    "test_dir = str() \n",
    "\n",
    "training_set= read_data(train_dir)\n",
    "testing_set = read_data(test_dir)\n",
    "\n",
    "v = CountVectorizer(analyzer=\"word\", tokenizer=None, preprocessor=None, stop_words= None, max_features=500)\n",
    "\n",
    "train_vectors = v.fit_transform(training_set['Description'])\n",
    "test_vectors = v.fit_transform(testing_set['Description'])\n",
    "\n",
    "Y = training_set['Personal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now build, train, and test our 5 models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(train_vectors, Y)\n",
    "\n",
    "testing_set['Logistic Regression Predictions'] = LR.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_estimators=100)\n",
    "RF.fit(train_vectors, Y)\n",
    "\n",
    "testing_set['Random Forest Predictions'] = RF.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "GNB = GaussianNB()\n",
    "GNB.fit(train_vectors.toarray(), Y)\n",
    "\n",
    "testing_set['GaussianNB Predictions'] = GNB.predict(test_vectors.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNB = MultinomialNB()\n",
    "MNB.fit(train_vectors, Y)\n",
    "\n",
    "testing_set['MultinomialNB Predictions'] = MNB.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(kernel = 'linear')\n",
    "SVM.fit(train_vectors, Y)\n",
    "\n",
    "testing_set['SVM Predictions'] = SVM.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If needed, we can save the results from our models to a csv (this is done in the next block of code). The models' results are saved in the dataframe `testing_set`  and can be viewed by calling it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set.to_csv('data/ModelOutput/' + train_dir[10:-4] + '+' + test_dir[10:-4] + '_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's construct a table that has the evaulation metrics of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = testing_set\n",
    "\n",
    "RF_metric = eval_model('RF', ts['Personal'], ts['Random Forest Predictions'])\n",
    "LR_metric = eval_model('LR', ts['Personal'], ts['Logistic Regression Predictions'])\n",
    "GNB_metric = eval_model('GNB', ts['Personal'], ts['GaussianNB Predictions'])\n",
    "MNB_metric = eval_model('MNB', ts['Personal'], ts['MultinomialNB Predictions'])\n",
    "SVM_metric = eval_model('SVM', ts['Personal'], ts['SVM Predictions'])\n",
    "\n",
    "metrics_list = [ RF_metric, LR_metric, GNB_metric, MNB_metric, SVM_metric]\n",
    "metrics = pd.DataFrame(metrics_list)\n",
    "metrics.to_csv('data/ModelOutput/' + train_dir[10:-4] + '+' + test_dir[10:-4] + '_metrics.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
